{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_size = (4608//10, 2592//10)\n",
    "\n",
    "def load_images(directory):\n",
    "    list_target_names = []\n",
    "    list_images = []\n",
    "        \n",
    "    for path, subdirs, files in os.walk(directory):\n",
    "        if(path.startswith(directory + '.')):\n",
    "            continue\n",
    "        files = [f for f in files if not f[0] == '.' and not f == 'desktop.ini'] # Ignore '.directory' file and desktop.ini\n",
    "        print(path, len(files))\n",
    "        for name in files:\n",
    "            \n",
    "            image = cv2.imread(os.path.join(path, name), cv2.IMREAD_REDUCED_GRAYSCALE_2)\n",
    "            # print(path, name)\n",
    "            if image is not None:\n",
    "                image = cv2.resize(image, resize_size, interpolation=cv2.INTER_AREA)\n",
    "                list_target_names.append(os.path.basename(path))\n",
    "                list_images.append(image)\n",
    "    \n",
    "    return list_target_names,  list_images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    global d;\n",
    "    Name=[]\n",
    "    for file in os.listdir(directory):\n",
    "        Name+=[file]\n",
    "    \n",
    "    #################################\n",
    "    d = defaultdict(int)\n",
    "    co = 0\n",
    "    for x in sorted(os.listdir(directory)):\n",
    "        if not x.startswith('.') and not d[x]:\n",
    "            d[x] = co\n",
    "            co+=1\n",
    "    #########################\n",
    "    target_names,images = load_images(directory)\n",
    "    #########################\n",
    "\n",
    "    target_names_shuffled, images_shuffled = shuffle(np.array(target_names), np.array(images))\n",
    "    \n",
    "    ############reshaping#############\n",
    "    n_samples, nx, ny= images_shuffled.shape\n",
    "\n",
    "    images_shuffled = images_shuffled.reshape(n_samples,-1)\n",
    "        \n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(images_shuffled, target_names_shuffled, random_state=0, test_size=0.2)\n",
    "\n",
    "    \n",
    "    return Xtrain, Xtest, ytrain, ytest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './Dataset_0-5/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30100\\1012942973.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbase_directory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./Dataset_0-5/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30100\\578977639.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mName\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './Dataset_0-5/'"
     ]
    }
   ],
   "source": [
    "base_directory = './Dataset_0-5/'\n",
    "X_train, X_test, Y_train, Y_test = load_data(base_directory)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with default/fixed paramaters and naive pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svc = Pipeline([('scalar1', StandardScaler()),\n",
    "                        ('pca1', PCA(n_components=2)),\n",
    "                        ('svc_classifier', svm.SVC())])\n",
    "\n",
    "pipeline_rf = Pipeline([('scalar1', StandardScaler()),\n",
    "                        ('pca2', PCA(n_components=2)),\n",
    "                        ('rf_classifier', RandomForestClassifier())])\n",
    "\n",
    "pipeline_sgd = Pipeline([('scalar1', StandardScaler()),\n",
    "                        ('pca3', PCA(n_components=2)),\n",
    "                        ('sgd_classifier', SGDClassifier())])\n",
    "\n",
    "pipeline_bayes = Pipeline([('scalar1', StandardScaler()),\n",
    "                        ('pca4', PCA(n_components=2)),\n",
    "                        ('bayes_classifier', GaussianNB())])\n",
    "\n",
    "pipeline_KNN = Pipeline([('scalar1', StandardScaler()),\n",
    "                        ('pca5', PCA(n_components=2)),\n",
    "                        ('KNN_classifier', KNeighborsClassifier(n_neighbors= 5))])\n",
    "\n",
    "pipeline_KMeans = Pipeline([('scalar1', StandardScaler()),\n",
    "                        ('pca6', PCA(n_components=2)),\n",
    "                        ('KMeans_classifier', KMeans(n_clusters = 6, random_state = 0, n_init='auto'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of pipelines\n",
    "pipelines = [pipeline_svc, pipeline_rf, pipeline_sgd, pipeline_bayes, pipeline_KNN, pipeline_KMeans]\n",
    "best_accuracy = 0.0\n",
    "best_clf = -1  # index of best classifier\n",
    "best_pipeline = \"\"\n",
    "pipe_dict = {0: 'SVC',\n",
    "             1: 'Random Forest',\n",
    "             2: 'SGD',\n",
    "             3: 'Bayes',\n",
    "             4: 'KNN',\n",
    "             5: 'KMeans'\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pipelines:\n",
    "    p.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Test accuracy: 0.19452054794520549\n",
      "Random Forest Test accuracy: 0.2136986301369863\n",
      "SGD Test accuracy: 0.14794520547945206\n",
      "Bayes Test accuracy: 0.2054794520547945\n",
      "KNN Test accuracy: 0.1726027397260274\n",
      "KMeans Test accuracy: -3153550.816000039\n"
     ]
    }
   ],
   "source": [
    "for i,p in enumerate(pipelines):\n",
    "    print(\"{} Test accuracy: {}\".format(pipe_dict[i], p.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with best accuracy: Random Forest\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(X_test, Y_test) > best_accuracy:\n",
    "        best_accuracy = model.score(X_test, Y_test)\n",
    "        best_pipeline = model\n",
    "        best_clf = i\n",
    "        \n",
    "print('Classifier with best accuracy: {}'.format(pipe_dict[best_clf]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TUNING:\n",
    "    clf_1 = svm.SVC()\n",
    "    param_grid_1 = {'C': [0.1, 1],#, 10, 100, 1000],\n",
    "                'gamma': [1, 0.1],# 0.01,  0.001,  0.0001],\n",
    "                'kernel': ['rbf']}#, 'linear']}\n",
    "    grid = GridSearchCV(clf_1, param_grid_1, refit=True, verbose=3)#, n_jobs= 1)\n",
    "\n",
    "    # fitting the model for grid search\n",
    "    grid.fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TUNING:\n",
    "\n",
    "    clf_2 = RandomForestClassifier()\n",
    "\n",
    "    param_grid_2 = {\n",
    "        'n_estimators': [25, 50, 100],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'max_depth': [3, 6, 9],\n",
    "        'max_leaf_nodes': [3, 6, 9],\n",
    "    }\n",
    "    grid = GridSearchCV(clf_2, param_grid_2, refit=True,\n",
    "                        verbose=3)  # , n_jobs= 1)\n",
    "\n",
    "    # fitting the model for grid search\n",
    "    grid.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TUNING:\n",
    "        \n",
    "    df = pd.DataFrame(grid.cv_results_)\n",
    "    df.to_csv('svc.csv')\n",
    "    print(grid.best_estimator_)\n",
    "    print(grid.best_params_)\n",
    "\n",
    "    df = pd.DataFrame(grid.cv_results_)\n",
    "    df.to_csv('random_forest.csv')\n",
    "    print(grid.best_estimator_)\n",
    "    print(grid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
